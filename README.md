# ğŸ” SecureRAG â€“ Multi-LLM Security & Verification Framework

SecureRAG is an end-to-end **LLM security and trust framework** designed to generate **safe, reliable, and verifiable AI responses**.
It combines **prompt-injection detection**, **Retrieval-Augmented Generation (RAG)**, and **cross-LLM verification** to prevent hallucinations, unsafe outputs, and malicious prompts.

---

## ğŸ“Œ Key Features

### âœ… Prompt Injection Detection

* Uses a **RoBERTa-based classifier** to detect malicious or adversarial prompts.
* Rule-based filters catch explicit instruction overrides (e.g., "ignore previous instructions").
* Blocks unsafe prompts **before** they reach the LLM.

### âœ… Secure Retrieval-Augmented Generation (RAG)

* Knowledge is retrieved using **FAISS vector search + sentence-transformer embeddings**.
* Responses are constrained strictly to retrieved context.
* Automatically falls back to general LLM only when no verified context exists.

### âœ… Multi-LLM Cross Verification

* Independently queries:

  * **Gemini**
  * **Cohere**
* Each model verifies the answer using a structured verdict format:

  * âœ… Yes / âŒ No / â“ Unsure
* Helps identify hallucinations and inconsistencies.

### âœ… Eligibility & Safety Scoring

Each response is evaluated on:

* Toxicity
* Banned topics
* Sensitive content
* Length constraints
* Language sanity

Produces a **final eligibility score** for every LLM output.

### âœ… Auto-Learning Knowledge Store

* When no RAG answer exists, the system:

  * Curates structured knowledge
  * Stores it back into the vector database
* Enables **continuous knowledge growth** without retraining.

### âœ… Interactive Gradio Dashboard

* Real-time query testing
* Displays:

  * Safety status (Blocked / Allowed)
  * RAG, Gemini, and Cohere answers
  * Verification verdicts
  * Eligibility scores
  * Sources used

---

## ğŸ—ï¸ System Architecture

```
User Query
   â†“
Prompt Injection Guard (RoBERTa + Rules)
   â†“
RAG Retrieval (FAISS + Embeddings)
   â†“
Gemini Answer (Context-restricted)
   â†“
Cross-LLM Verification (Gemini + Cohere)
   â†“
Safety & Eligibility Scoring
   â†“
Gradio UI Dashboard
```

---

## ğŸ› ï¸ Tech Stack

### Core

* **Python**
* **PyTorch**
* **Hugging Face Transformers**

### AI / NLP

* **RoBERTa** (Prompt Injection Detection)
* **Sentence-Transformers**
* **Gemini API**
* **Cohere API**

### Retrieval

* **FAISS**
* **Dense Vector Embeddings**

### Security & Safety

* Prompt Injection Protection
* Hallucination Detection
* Cross-Model Validation
* Eligibility & Trust Scoring

### UI & Platform

* **Gradio**
* **Google Colab**
* **Google Drive Integration**

---

## ğŸš€ Getting Started (Google Colab)

### 1ï¸âƒ£ Open Notebook in Colab

Upload the project notebook to Google Colab.

### 2ï¸âƒ£ Install Dependencies

```bash
pip install sentence-transformers transformers accelerate faiss-cpu google-generativeai cohere gradio
```

> **Note:** For reproducible builds, you may specify versions or use a `requirements.txt` file.

### 3ï¸âƒ£ Mount Google Drive

```python
from google.colab import drive
drive.mount('/content/drive')
```

### 4ï¸âƒ£ Set API Keys

```python
import os
os.environ["GOOGLE_API_KEY"] = "YOUR_GEMINI_KEY"
os.environ["COHERE_API_KEY"] = "YOUR_COHERE_KEY"
```

> âš ï¸ **Security Warning:** Never hardcode API keys in your source code. Use environment variables, secret management services, or Colab's Secrets feature to securely manage credentials.

### 5ï¸âƒ£ Place Required Data

* RoBERTa model:

```
/content/drive/MyDrive/<your-project-folder>/roberta_model_best/
```

* Knowledge text files:

```
/content/drive/MyDrive/<your-project-folder>/data/processed/
```

> **Note:** Replace `<your-project-folder>` with your actual Google Drive project directory path.

### 6ï¸âƒ£ Run the Gradio UI

```python
demo.launch(share=True)
```

---

## ğŸ–¥ï¸ Gradio UI Output

The dashboard displays:

* âœ… **Query Safety Status**
* ğŸ“„ **RAG Answer**
* ğŸ¤– **Gemini Answer**
* ğŸ§  **Cohere Answer**
* ğŸ§ª **Verification Verdicts**
* ğŸ“Š **Eligibility Scores**
* ğŸ”— **Knowledge Sources**

---

## ğŸ“Š Sample Output (Simplified)

```json
{
  "blocked": false,
  "rag": { "answer": "...", "eligibility": { "ec_score": 5 } },
  "gemini": { "answer": "...", "eligibility": { "ec_score": 5 } },
  "cohere": { "answer": "...", "eligibility": { "ec_score": 5 } }
}
```

---

## ğŸ¯ Use Cases

* Secure enterprise LLM systems
* AI safety research
* Hallucination-resistant chatbots
* Knowledge-first AI assistants
* Trustworthy AI frameworks

---

## ğŸŒŸ Why SecureRAG?

âœ” Not just a chatbot
âœ” Focused on **AI Safety & Trust**
âœ” Implements **real-world LLM security techniques**
âœ” Interview-ready & resume-strong project

---

## ğŸ‘¤ Author

**Meghana Gudise**
ğŸ“ Computer Science | AI & ML
ğŸ”— GitHub: [https://github.com/GudiseMeghana](https://github.com/GudiseMeghana)

---

## â­ If you find this project useful

Give it a â­ and feel free to fork or contribute!
